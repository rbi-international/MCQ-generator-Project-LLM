{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.getenv(\"OPEN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MCQ_Generator\\MCQ-generator-Project-LLM\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(openai_api_key = key, model_name = \"gpt-3.5-turbo\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000016618FE3F70>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000016618FF2A00>, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESPONSE_JSON = {\n",
    "#     \"1\": {\n",
    "#         \"mcq\": \"multiple choice question\",\n",
    "#         \"options\": {\n",
    "#             \"a\": \"choice here\",\n",
    "#             \"b\": \"choice here\",\n",
    "#             \"c\": \"choice here\",\n",
    "#             \"d\": \"choice here\",\n",
    "#         },\n",
    "#         \"correct\": \"correct answer\",\n",
    "#     },\n",
    "#     \"2\": {\n",
    "#         \"mcq\": \"multiple choice question\",\n",
    "#         \"options\": {\n",
    "#             \"a\": \"choice here\",\n",
    "#             \"b\": \"choice here\",\n",
    "#             \"c\": \"choice here\",\n",
    "#             \"d\": \"choice here\",\n",
    "#         },\n",
    "#         \"correct\": \"correct answer\",\n",
    "#     },\n",
    "#     \"3\": {\n",
    "#         \"mcq\": \"multiple choice question\",\n",
    "#         \"options\": {\n",
    "#             \"a\": \"choice here\",\n",
    "#             \"b\": \"choice here\",\n",
    "#             \"c\": \"choice here\",\n",
    "#             \"d\": \"choice here\",\n",
    "#         },\n",
    "#         \"correct\": \"correct answer\",\n",
    "#     },\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\MCQ_Generator\\MCQ-generator-Project-LLM\\Response.json\", \"r\") as f:\n",
    "    RESPONSE_JSON = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'mcq': 'multiple choice question', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}, '2': {'mcq': 'multiple choice question', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}, '3': {'mcq': 'multiple choice question', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}}\n"
     ]
    }
   ],
   "source": [
    "print(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'mcq': 'multiple choice question', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}, '2': {'mcq': 'multiple choice question', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}, '3': {'mcq': 'multiple choice question', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\",\"response_json\"],\n",
    "    template = TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(llm = llm, prompt = quiz_generation_prompt, output_key = \"quiz\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=TEMPLATE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "                                        output_variables=[\"quiz\", \"review\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"D:\\MCQ_Generator\\MCQ-generator-Project-LLM\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\MCQ_Generator\\MCQ-generator-Project-LLM\\data.txt\n"
     ]
    }
   ],
   "source": [
    "print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH, \"r\") as f:\n",
    "    TEXT = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent progress in generative models have resulted in models that can produce realistic text, images and video that can potentially revolutionize the way humans work, create content and interact with machines. The workshop on Generative AI at AIMLSystems will focus on the entire life-cycle of building and deploying such Generative AI systems, including data collection and processing, developing systems and requisite infrastructure, applications it enables, and the ethics associated with such technology covering concerns related to fairness, transparency and accountability. We invite original, unpublished work on Artificial Intelligence with a focus on generative AI and their use cases. Specifically, the topics of interest include but are not limited to:\n",
      "\n",
      "Systems, architecture and infrastructure for Generative AI\n",
      "Machine learning and Modeling using LLMs and Diffusion models\n",
      "Large Language Models and its applications\n",
      "Multi-modal Generative AI and its applications\n",
      "Gen AI based Plugins and agents\n",
      "Deployment of Generative AI solutions\n",
      "Evaluation of Language and Diffusion based models\n",
      "Responsible use of Gen AI\n"
     ]
    }
   ],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=5 \n",
    "SUBJECT=\"AI\"\n",
    "TONE=\"Simple\"\n",
    "RESPONSE_JSON=\"Response_json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    generate_evaluate_chain(\n",
    "        \"text\": \n",
    "        \"number\":\n",
    "        \"subject\":\n",
    "        \"tone\":\n",
    "        \"RESPONSE_JSON\":\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
